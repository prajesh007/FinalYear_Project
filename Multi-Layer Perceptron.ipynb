{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "937c4f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb3aaf2",
   "metadata": {},
   "source": [
    "# Softmax Function\n",
    "\n",
    "Used to form Probabiity Distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "705a1937",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def sigmoid(z):\n",
    "    #return (1.0)/(1+np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc2b63fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(a):\n",
    "    # [2,4,3,5]\n",
    "    # e^i/(summation of e^i)\n",
    "    # e^2/(e^2+...+e^5)\n",
    "    e_pa=np.exp(a)\n",
    "    ans=e_pa/np.sum(e_pa, axis=1, keepdims=True)\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63d7d244",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewNeuralNetwork:\n",
    "    \n",
    "    def __init__(self, input_size, layers, no_of_layers, output_size):\n",
    "        \n",
    "        np.random.seed(0)\n",
    "        \n",
    "        total_layers=[input_size] #total_layers=[2]\n",
    "        total_layers.extend(layers) #[2,4,3]\n",
    "        total_layers.append(output_size) #[2,4,3,2]\n",
    "        layers=total_layers\n",
    "        no_of_layers+=2\n",
    "        \n",
    "        model={} # model[i] = (wi, bi)\n",
    "        \n",
    "        # Implementation of MLP\n",
    "        for i in range (no_of_layers-1):\n",
    "            \n",
    "            model[i] = [np.random.randn(layers[i], layers[i+1]), np.zeros((1, layers[i+1]))]\n",
    "        \n",
    "        self.model=model\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "            \n",
    "        count=1\n",
    "        \n",
    "        model_size=len(self.model)\n",
    "            \n",
    "        temp_model=self.model\n",
    "        \n",
    "        for key in self.model:\n",
    "             \n",
    "            if count==1:\n",
    "                    \n",
    "                z=np.dot(x, temp_model[key][0]) + temp_model[key][1] # model[2]=(w3,b3) model[2][0]=w3  model[2][1]=b3\n",
    "                a=np.tanh(z)\n",
    "                \n",
    "                \n",
    "            elif count == model_size:\n",
    "                \n",
    "                z=np.dot(a, temp_model[key][0]) + temp_model[key][1]\n",
    "                y_ = softmax(z)\n",
    "                return y_\n",
    "                \n",
    "                \n",
    "                \n",
    "                    \n",
    "            else:\n",
    "                z=np.dot(a, temp_model[key][0]) + temp_model[key][1]\n",
    "                a=np.tanh(z)\n",
    "                \n",
    "                                 \n",
    "            \n",
    "            count+=1\n",
    "                    \n",
    "                    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "381a7838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input the no. of samples....4\n",
      "Input the number of features (number of Neurons in i/p layer)....5\n",
      "Enter the no. of hidden layes....4\n",
      "enter the size of the layer  1 ....\n",
      "1\n",
      "enter the size of the layer  2 ....\n",
      "2\n",
      "enter the size of the layer  3 ....\n",
      "3\n",
      "enter the size of the layer  4 ....\n",
      "4\n",
      "enter the number of classes in o/p layer....5\n",
      "output: \n",
      " [[0.03391486 0.04416114 0.06573533 0.80860554 0.04758313]\n",
      " [0.03391465 0.04416089 0.06573558 0.80860633 0.04758255]\n",
      " [0.03631421 0.04688552 0.06535195 0.79888052 0.05256781]\n",
      " [0.03391379 0.04415983 0.06573661 0.80860963 0.04758014]]\n",
      "\n",
      "\n",
      "\n",
      "Sample  1  belongs to class...3\n",
      "Sample  2  belongs to class...3\n",
      "Sample  3  belongs to class...3\n",
      "Sample  4  belongs to class...3\n"
     ]
    }
   ],
   "source": [
    "# Model Parameters\n",
    "sample_size=int(input(\"Input the no. of samples....\")) #number of samples\n",
    "input_size=int(input(\"Input the number of features (number of Neurons in i/p layer)....\")) # number of features\n",
    "no_of_layer=int(input(\"Enter the no. of hidden layes....\"))\n",
    "layers=[] # Number of Neurons in each Layer\n",
    "for i in range (no_of_layer):\n",
    "    print(\"enter the size of the layer \",(i+1),\"....\")\n",
    "    temp=int(input())\n",
    "    layers.append(temp)\n",
    "    \n",
    "output_size=int(input(\"enter the number of classes in o/p layer....\"))\n",
    "\n",
    "\n",
    "n=NewNeuralNetwork(input_size, layers, no_of_layer, output_size)\n",
    "\n",
    "\n",
    "x=np.random.randn(sample_size, input_size)\n",
    "output_matrix=n.forward(x)\n",
    "print('output: \\n', output_matrix)\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "s=1\n",
    "for i in output_matrix:\n",
    "    print(\"Sample \",s,\" belongs to class...\",end=\"\")\n",
    "    print(next(j for j, x in enumerate(i) if x == max(i)))\n",
    "    s+=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
